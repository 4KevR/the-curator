import itertools
import pathlib
from dataclasses import dataclass
from typeguard import typechecked

from src.backend.modules.evaluation.load_test_data.import_data_classes import _Test_ExpectedResult, _Test_Data
from src.backend.modules.srs.testsrs.testsrs import TestFlashcardManager, Flag, CardState, TestDeck


# ####################################################################################################################
# # Clean dataclasses for the test data
#
# The tests are parsed from the test.json, and are represented as TestFlashcardManagers â€“ they are working
# AbstractFlashcardManagers.
# The TestFlashcardManagers are frozen, and need to be copied to be modified.
#
# Only the "load_test_data" method is public.
#
# ####################################################################################################################

@dataclass(frozen=True)
@typechecked
class InteractionTest:
    name: str
    description: str
    environment: TestFlashcardManager
    queries: list[str]
    parameters: dict[str, str]
    expected_result: TestFlashcardManager
    sound_file_names: list[str]


@dataclass(frozen=True)
@typechecked
class QuestionAnsweringTest:
    name: str
    category: str
    description: str
    environment: TestFlashcardManager
    queries: list[list[str]]
    expected_answer: str
    sound_file_name: str


@dataclass(frozen=True)
@typechecked
class EvaluationTests:
    """
    The evaluation tests.
    """
    test_flashcard_manager: TestFlashcardManager  # not really necessary, but nice to have.
    interaction: list[InteractionTest]
    question_answering: list[QuestionAnsweringTest]


def replace_many(s: str, replacements: dict[str, str]) -> str:
    """
    Replace multiple substrings in a string. There is no guarantee on the order of replacements.
    """
    for old, new in replacements.items():
        s = s.replace(old, new)
    return s


@dataclass(frozen=True)
class _ParsedPrompt:
    parsed_prompt_sequence: list[str]
    parameters: dict[str, str]
    audio_file_suffixes: list[str]


def _get_prompt_with_parameters(
        prompts: list[list[str]], parameters: dict[str, list[str]]
) -> list[_ParsedPrompt]:
    """
    Parses prompt alternatives with parameter templates (example: <example>).
    The audio_file_suffixes returned are the same that were generated by recording.py and can be used to match
    audio recordings to test cases.

    Example:
        Prompts: [["Please explain what a <subject> is.", "What is a <subject>?"], ["Please explain in Chinese."]]
        Parameters: {"subject": ["arthropod", "monokaryotic mycelium"]}

    Returns:
        [
            _ParsedPrompt(
                parsed_prompt_sequence=["Please explain what a arthropod is.", "Please explain in Chinese."],
                parameters={"subject": "arthropod"},
                audio_file_suffixes=["_prm_0"]
            ),
            _ParsedPrompt(
                parsed_prompt_sequence=["Please explain what a monokaryotic mycelium is.", "Please explain in Chinese."],
                parameters={"subject": "monokaryotic mycelium"},
                audio_file_suffixes=["_prm_1"]
            )
        ]
    """
    # First: Get all possible substitutions.
    keys = parameters.keys()
    keys_with_angles = [f"<{it}>" for it in keys]
    values = parameters.values()
    indices = [range(len(it)) for it in values]

    only_zip = "join" in parameters and parameters.pop("join") == "zip"

    if not only_zip:  # cross product
        combinations = itertools.product(*values)
        combinations_idx = itertools.product(*indices)
    else:  # zip
        assert len({len(it) for it in parameters.values()}) <= 1, \
            "all parameters must have the same length"
        combinations = zip(*values)
        combinations_idx = zip(*indices)

    raw_substitutions: list[dict[str, str]] = [
        dict(zip(keys_with_angles, combination)) for combination in combinations
    ]

    # get the substitutions with the ids used for audio file names
    substitutions_with_ids = zip(raw_substitutions, combinations_idx)

    # Second: Get all possible prompt combinations (steps):
    # (no idea what goes wrong here. It is clearly int, not Any).
    # noinspection PyTypeChecker
    step_combinations_ids: list[tuple[int]] = list(itertools.product(*[list(range(len(it))) for it in prompts]))
    # noinspection PyTypeChecker
    step_combinations_raw: list[tuple[str]] = list(itertools.product(*[it for it in prompts]))

    # Third: Combine.
    res = []

    for step_combinations_id, step_combination_raw in zip(step_combinations_ids, step_combinations_raw):
        for (substitution, ids) in substitutions_with_ids:
            if len(parameters) == 0:
                substitution_ids = ""
            else:
                substitution_ids = "_prm_" + "_".join(str(x) for x in ids)

            parsed_prompt_sequences = [replace_many(it, substitution) for it in step_combination_raw]
            audio_file_suffixes = [
                (f"_multistep_{step_id}_{prompt_id}" if len(prompts) != 1 else f"_{prompt_id}") + substitution_ids
                # step id: The n-th query. Always 0, 1, 2, ..., 3. prompt_id: The prompt selected for this step.
                for (step_id, prompt_id) in enumerate(step_combinations_id)
            ]

            res.append(_ParsedPrompt(
                parsed_prompt_sequence=parsed_prompt_sequences,
                parameters=substitution,
                audio_file_suffixes=audio_file_suffixes
            ))
    return res


def _expected_result_to_fcm(
        expected_result: _Test_ExpectedResult,
        parameter_replacements: dict[str, str],
        known_decks: dict[str, TestDeck]
) -> TestFlashcardManager:
    """
    This function turns a _Test_ExpectedResult into a TestFlashcardManager. If a known deck is referenced in a
    _Test_ExpectedResult, the deck is copied. Parameter templates present in parameter_replacements are replaced
    (Card: question, answer, flag, card_state; Deck: deck_name).
    """
    # Create flashcard manager and replace parameters in deck names, questions and answers.
    fcm = TestFlashcardManager()
    for deck in expected_result.decks:
        if isinstance(deck, str):
            if deck not in known_decks:
                raise ValueError(f"Unknown deck name: {deck}")
            known_deck = known_decks[deck]
            fcm_deck = fcm.add_deck(replace_many(known_deck.name, parameter_replacements))
            for card in known_deck.cards:
                fcm.add_full_card(
                    deck=fcm_deck,
                    question=replace_many(card.question, parameter_replacements),
                    answer=replace_many(card.answer, parameter_replacements),
                    flag=card.flag,
                    card_state=card.cardState,
                    # No fuzzy matching here.
                )
        else:
            fcm_deck = fcm.add_deck(replace_many(deck.name, parameter_replacements))
            for card in deck.cards:
                fcm.add_full_card(
                    deck=fcm_deck,
                    question=replace_many(card.question, parameter_replacements),
                    answer=replace_many(card.answer, parameter_replacements),
                    flag=Flag.from_str(replace_many(card.flag, parameter_replacements)),
                    card_state=CardState.from_str(replace_many(card.cardState, parameter_replacements)),
                    fuzzymatch_question="question" in card.field_fuzzymatch,
                    fuzzymatch_answer="answer" in card.field_fuzzymatch,
                )

    fcm.freeze()
    return fcm


def _parse_tests(
        test_data: _Test_Data,
        known_decks: dict[str, TestDeck],
        known_environments: dict[str, TestFlashcardManager],
) -> tuple[list[InteractionTest], list[QuestionAnsweringTest]]:
    """
    Parses the interaction tests ("tests" in json) and question answering tests ("question_answering" in json)
    into useful classes (InteractionTest, QuestionAnsweringTest).
    """
    interaction_tests = [
        InteractionTest(
            name=test.name,
            description=test.description,
            environment=known_environments[test.environment],
            queries=parsed_prompt.parsed_prompt_sequence,
            expected_result=_expected_result_to_fcm(test.expected_result, parsed_prompt.parameters, known_decks),
            parameters=parsed_prompt.parameters,
            sound_file_names=[test.name + audio_file_suffix for audio_file_suffix in parsed_prompt.audio_file_suffixes]
        )
        for test in test_data.tests
        for parsed_prompt in _get_prompt_with_parameters(test.queries, (test.params or {}))
    ]

    question_answering_tests = []

    for category in test_data.question_answering:
        for test in test_data.question_answering[category]:
            for (step_id, step) in enumerate(test.queries):
                for (prompt_id, prompt_template) in enumerate(step):
                    question_answering_tests.append(QuestionAnsweringTest(
                        name=test.name,
                        category=category,
                        description=test.description,
                        environment=known_environments[test.environment].copy(),
                        queries=test.queries,
                        expected_answer=test.expected_answer,
                        sound_file_name=test.name + (
                            f"_multistep_{step_id}_{prompt_id}" if len(test.queries) > 1 else f"_{prompt_id}"),
                    ))

    return interaction_tests, question_answering_tests


def _parse_test_environments(data: _Test_Data) -> tuple[
    TestFlashcardManager, dict[str, TestFlashcardManager], dict[str, TestDeck]]:
    """
    Parses the
     * test decks ("test_decks") into a master flashcard manager
     * test environments ("dummy_environments" in json) into flashcard managers

    Returns:
        The master flashcard manager, a dictionary of environments by environment key, and a dictionary of decks by deck key.
    """
    key_to_srs_deck: dict[str, TestDeck] = {}

    # Parse the decks into a master fcm
    test_fcm = TestFlashcardManager()
    for (deck_key, deck) in data.test_decks.items():
        srs_deck = test_fcm.add_deck(deck.name)
        key_to_srs_deck[deck_key] = srs_deck
        for card in deck.cards:
            test_fcm.add_full_card(
                deck=srs_deck,
                question=card.question,
                answer=card.answer,
                flag=Flag.from_str(card.flag),
                card_state=CardState.from_str(card.cardState)
            )
    test_fcm.freeze()

    # Create the dummy environments as flashcard managers
    environments: dict[str, TestFlashcardManager] = {}

    for (dummy_envir_key, dummy_envir) in data.dummy_environments.items():
        dummy_fcm = TestFlashcardManager()
        environments[dummy_envir_key] = dummy_fcm

        for deck_key in dummy_envir.decks:
            source_deck = key_to_srs_deck[deck_key]
            target_deck = dummy_fcm.add_deck(source_deck.name)
            for card in source_deck.cards:
                dummy_fcm.add_full_card(
                    deck=target_deck,
                    question=card.question,
                    answer=card.answer,
                    flag=card.flag,
                    card_state=card.cardState
                )

        dummy_fcm.freeze()

    return test_fcm, environments, key_to_srs_deck


def load_test_data(path: str) -> EvaluationTests:
    """
    Parses the test data from a json file into an EvaluationTests object for easy use.
    The EvaluationTests contain the test environments and the expected test results as TestFlashcardManagers
    (subclass of AbstractFlashcardManager) for easy evaluation/usage.
    """
    json_path = pathlib.Path(path)
    data = _Test_Data.model_validate_json(json_path.read_text(encoding="utf-8"))

    (flashcard_manager, known_environments, known_decks) = _parse_test_environments(data)

    interaction_tests, question_answering_tests = _parse_tests(data, known_decks, known_environments)

    return EvaluationTests(flashcard_manager, interaction_tests, question_answering_tests)
